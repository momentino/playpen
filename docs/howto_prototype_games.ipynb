{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b036239-7b35-4856-8df3-11126c855cf2",
   "metadata": {},
   "source": [
    "**NOTE 2024-08-23** This assumes that `encode_messages in the `openai_api` has been fixed to not touch messages whose content is only text anymore. I've applied this fix locally, but need to confirm that it's ok.  TO REVISIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "779d31f0-150c-4426-b71c-5273aa0f439f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:54.714392Z",
     "start_time": "2024-02-19T11:09:54.489658Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e5a72d3-f9ff-4bb5-a423-a30c60cf2318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:54.717139Z",
     "start_time": "2024-02-19T11:09:54.496073Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('/Users/das/work/local/Gits/2024/clembench-das')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e70b4a-1467-4204-b639-faffeb21452c",
   "metadata": {},
   "source": [
    "# Prototyping Dialogue Games with and for `clemgame`\n",
    "\n",
    "This notebook demonstrates how the package can be used to prototype a game: play around with prompts, define the MOVE RULEs and the GAME RULEs (see below), and set up the game loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e99adfa-965e-4ee5-b1d1-e7c8d5a139db",
   "metadata": {},
   "source": [
    "## Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dddd346-9ac4-4873-bca7-2ae19eba64eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.169899Z",
     "start_time": "2024-02-19T11:09:54.514926Z"
    }
   },
   "outputs": [],
   "source": [
    "from backends import ModelSpec, Model, get_model_for, load_model_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61835ae51ed11b39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.170214Z",
     "start_time": "2024-02-19T11:09:54.521466Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "load_model_registry() # load default model registry from backends folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55856426-c8b1-4b58-b0f3-57cb9e7d854d",
   "metadata": {},
   "source": [
    "Models are identified via their entry in the model registry, and subsequently loaded.\n",
    "\n",
    "There are many ways to get at the model (check out the `model_backend_registry_readme.md`). The simplest is to just give the lookup function a model name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5ba938-bbdf-4215-a753-e6e0b6bf3306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.179639Z",
     "start_time": "2024-02-19T11:09:54.526857Z"
    }
   },
   "outputs": [],
   "source": [
    "THIS_MODEL = 'gpt-3.5-turbo-1106' # fails if no registered entry\n",
    "llm: Model = get_model_for(THIS_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc8336a-cce8-4842-ad95-5341d73968d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.179937Z",
     "start_time": "2024-02-19T11:09:54.531412Z"
    }
   },
   "outputs": [],
   "source": [
    "# THIS_MODEL = 'gpt-5-super-AGI' # fails if no registered entry\n",
    "# llm: Model = get_model_for(THIS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc679b34-329b-4799-aa8c-6e0be7c4d485",
   "metadata": {},
   "source": [
    "You can also pass a dictionary or a full `ModelSpec` object to the lookup function. The lookup function will try to unify this description with each spec in the registry. This is a way of *adding* information to an existing entry. If no existing entry unifies, this is a way of providing a spec even if there is no entry. (Whether this works depends on whether the specified backend is able to do something with the information it gets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f48833599e63dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.222553Z",
     "start_time": "2024-02-19T11:09:54.539329Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THIS_MODEL = dict(model_name=\"good-old-chatgpt\", model_id=\"gpt-3.5-turbo-1106\", backend=\"openai\") # works without registered entry when openai_api.py backend is available\n",
    "llm: Model = get_model_for(THIS_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e2e9e6ee3d08f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.232084Z",
     "start_time": "2024-02-19T11:09:54.544327Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "THIS_MODEL = ModelSpec(model_name=\"gpt-3.5-turbo-1106\", backend=\"openai\") # works without registered entry when openai_api.py backend is available\n",
    "llm: Model = get_model_for(THIS_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c648ba-01cb-4ec6-acb0-2fa25c06f5f9",
   "metadata": {},
   "source": [
    "Enough of this though. Let's get a good model to play around with, and leave it at that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6277d1b5-c211-4cb5-8719-ea9a0f05a962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.939436Z",
     "start_time": "2024-02-19T11:09:54.550368Z"
    }
   },
   "outputs": [],
   "source": [
    "THIS_MODEL = 'gpt-4o-mini-2024-07-18'\n",
    "llm: Model = get_model_for(THIS_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af3f3308-5f44-4745-9bbf-c45d16d261c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.939826Z",
     "start_time": "2024-02-19T11:09:55.398817Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "llm.set_gen_args(temperature = 0.0, max_tokens= 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7cda6a1-7462-4652-b5ef-d477c3507402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.948964Z",
     "start_time": "2024-02-19T11:09:55.409867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[0;31mSignature:\u001B[0m \u001B[0mllm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate_response\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessages\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mDict\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTuple\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;31mDocstring:\u001B[0m\n",
       ":param messages: for example\n",
       "        [\n",
       "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
       "            {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
       "            {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
       "            {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
       "        ]\n",
       ":return: the continuation\n",
       "\u001B[0;31mFile:\u001B[0m      ~/work/local/Gits/2024/clembench-das/backends/openai_api.py\n",
       "\u001B[0;31mType:\u001B[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?llm.generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2566b431-0a22-4c3d-b74a-7164988e40a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.998262Z",
     "start_time": "2024-02-19T11:09:55.419646Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_message(context, msg, role='user', sysmsg = 'You are a helpful assistant'):\n",
    "    if context == []:\n",
    "        context = [\n",
    "            {\"role\": \"system\", \"content\": sysmsg}\n",
    "        ]\n",
    "    context.append({\"role\": role, \"content\": msg})\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d140c6fc-ecfe-4d7a-8f59-67d2b224f58f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:55.999026Z",
     "start_time": "2024-02-19T11:09:55.436104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant'},\n",
       " {'role': 'user', 'content': 'hello, how are you?'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_message([], \"hello, how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3237f33e-42a1-40bc-aaa8-8f0ea832b686",
   "metadata": {},
   "source": [
    "Let us try a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e955b40-6ff1-4795-b855-640fee18247a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:58.003537Z",
     "start_time": "2024-02-19T11:09:55.455621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking is a systematic process used to evaluate and compare the performance, processes, or practices of an organization against those of other organizations, industry standards, or best practices. The primary goal of benchmarking is to identify areas for improvement, enhance efficiency, and achieve competitive advantage.\n",
      "\n",
      "There are several types of benchmarking, including:\n",
      "\n",
      "1. **Internal Benchmarking**: Comparing performance metrics within different departments or units of the same organization.\n",
      "\n",
      "2. **Competitive Benchmarking**: Comparing an organization's performance with that of its\n"
     ]
    }
   ],
   "source": [
    "prompt = add_message([], \"What is benchmarking?\")\n",
    "prompt, resp, resp_text = llm.generate_response(prompt)\n",
    "print(resp_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0a5a4-961e-4914-a13e-c8a1430cd42a",
   "metadata": {},
   "source": [
    "## Prototyping a game\n",
    "\n",
    "To set up a game, we need two things. First, we need what we shall call a MOVE RULE. This (kind of) rule defines what *form* a valid game move must take. (Having this form enables us to parse it and to even understand in the first place what the move was. For example, if we were to play chess and we would define that requested moves have to follow the [UCI](https://en.wikipedia.org/wiki/Universal_Chess_Interface) notation, then `e2e4` would validate (because it is in that format), and `Nf3` would not (and neither would the text `I will move my knight to F3` and similar).\n",
    "\n",
    "This is independent of the question of whether `e2e4` is a legal move in the current game state. These kinds of things are defined by the GAME RULEs. These rules determine what effect valid (= well-formed) moves have on the current game state: whether they are legal, and whether they update the game state, and if so, whether they perhaps even update the game into a goal state. We might also want to define other criteria that determine whether the game goes on or not, like a limit on the number of turns the game is played.\n",
    "\n",
    "What is important to keep in mind when setting up a clemgame is that both move and game rules need to be checkable *programmatically* (by the game master that you need to implement). That is, it shouldn't require the kind of \"intelligence\" that you want to test in the first place. Anything that is formally define-able should be ok.\n",
    "\n",
    "Let's try a very simple game. A and B are supposed to have a conversation, but in each of their turns, the first letter must be such that taken together, the sequence of first letters follows the sequence in the alphabet, with a given starting letter. So if that starting letter is 'h', the first utterance start with h, the second with i, and so on. This is the GAME RULE. If any player violates that rule, the game ends as a failure. If however the rule has not been violated for $n$ turns, it's a success. (The MOVE RULE is \"start your utterance with 'I SAY:'\". If the output of the player does not have this form, it is rejected. This can lead to a re-prompt (explaining again the move rule), or it can lead to the game being abandoned.)\n",
    "\n",
    "(This is not a terribly good game, as it does not require the integration of information across very many turns -- you just need to look at the previous turn to know which letter you are supposed to use. We might like to impose the constraint that the turns need to stick to a certain topic -- and indeed we will do so in the prompts below -- but that isn't something that we can test. Or at least not easily, and we won't attempt to here. But the game shall suffice to explain the basic concepts, and demonstrate the process of prototyping a game idea.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bce254-a1f6-4b32-9134-ff9cb1d4457b",
   "metadata": {},
   "source": [
    "#### The initial prompts\n",
    "\n",
    "Let's first try to find a good initial prompt for player A, who kicks things off. (Here it took me a couple of iterations to find the following prompt. We'll use that to continue.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5ada343-abaf-465b-92fd-e59ec5e4ffa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:58.003941Z",
     "start_time": "2024-02-19T11:09:57.968930Z"
    }
   },
   "outputs": [],
   "source": [
    "init_prompt_A = Template('''Let us play a game. I will tell you a topic and you will give me a short sentence that fits to this topic.\n",
    "But I will also tell you a letter. The sentence that you give me has to start with this letter.\n",
    "After you have answered, I will give you my reply, which will start with the letter following your letter in the alphabet.\n",
    "Then it is your turn again, to produce a reply starting with the letter following that one. And so on. Let's go.\n",
    "Start your utterance with I SAY: and do no produce any other text.\n",
    "The topic is: $topic\n",
    "The letter is: $letter''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4e15412-84d4-4704-a4fa-a6e286111e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:09:58.084830Z",
     "start_time": "2024-02-19T11:09:57.986525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let us play a game. I will tell you a topic and you will give me a short sentence that fits to this topic.\\nBut I will also tell you a letter. The sentence that you give me has to start with this letter.\\nAfter you have answered, I will give you my reply, which will start with the letter following your letter in the alphabet.\\nThen it is your turn again, to produce a reply starting with the letter following that one. And so on. Let's go.\\nStart your utterance with I SAY: and do no produce any other text.\\nThe topic is: birds\\nThe letter is: h\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic = 'birds'\n",
    "letter = 'h'\n",
    "init_prompt_A.substitute(topic=topic, letter=letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6bbf3-dc5f-4950-94bd-5dc2893873c8",
   "metadata": {},
   "source": [
    "Let us see what the model makes of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4714bd29-c9b6-41cc-a3e3-ec039c5850b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:13.661644Z",
     "start_time": "2024-02-19T11:10:12.436603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I SAY: Hummingbirds are known for their incredible speed and agility in flight.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_A, resp, resp_text = llm.generate_response(add_message([], init_prompt_A.substitute(topic='birds', letter='h')))\n",
    "resp_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b32e91-ce60-403b-9478-8b4b36d36f87",
   "metadata": {},
   "source": [
    "Not too bad! Let's code the MOVE RULE (and use it to get at the text itself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f1ea0f7-c23c-425a-b40a-62e072feb1fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:15.661203Z",
     "start_time": "2024-02-19T11:10:15.625278Z"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'I SAY: '\n",
    "def parse_reply(text, prefix=prefix):\n",
    "    if not text.startswith(prefix):\n",
    "        return False\n",
    "    return text[len(prefix):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb75b71-fcaf-47c1-a853-fbab797995fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:18.048284Z",
     "start_time": "2024-02-19T11:10:18.041999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hummingbirds are known for their incredible speed and agility in flight.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_reply(resp_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b920f9-6990-4f74-8e6f-d4617320b61b",
   "metadata": {},
   "source": [
    "Now we need the GAME RULE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fcd1aa3-aced-48d2-82f4-9fc4f50e495a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:22.057494Z",
     "start_time": "2024-02-19T11:10:22.014247Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_move(text, letter):\n",
    "    token = text.split()\n",
    "    if token[0][0].lower() == letter: # and token[-1][0].lower() == letter:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82a16807-80cd-4efe-9369-34b7372577ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:24.000475Z",
     "start_time": "2024-02-19T11:10:23.959658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_move(parse_reply(resp_text), letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b18560-d996-4d78-ace0-9510a9c14f02",
   "metadata": {},
   "source": [
    "Alright! Now for player B, who needs a slightly different prompt (as they *continue* the conversation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62fd1601-96e3-482d-a979-997f0884e65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:26.254674Z",
     "start_time": "2024-02-19T11:10:26.245532Z"
    }
   },
   "outputs": [],
   "source": [
    "init_prompt_B = Template('''Let us play a game. I will give you a sentence.\n",
    "The first word in my sentence starts with a certain letter.\n",
    "I want you to give me a sentence as a reply, with the same topic as my sentence, but different from my sentence.\n",
    "The first word of your sentence should start with the next letter in the alphabet from the letter my sentence started with.\n",
    "Let us try to have a whole conversation like that.\n",
    "Please start your reply with 'I SAY:' and do not produce any other text.\n",
    "Let's go.\n",
    "My sentence is: $sentence\n",
    "What do you say?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "447c2691-9dbc-4a8e-a61d-ddcac307da17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:28.080544Z",
     "start_time": "2024-02-19T11:10:28.054519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let us play a game. I will give you a sentence.\\nThe first word in my sentence starts with a certain letter.\\nI want you to give me a sentence as a reply, with the same topic as my sentence, but different from my sentence.\\nThe first word of your sentence should start with the next letter in the alphabet from the letter my sentence started with.\\nLet us try to have a whole conversation like that.\\nPlease start your reply with 'I SAY:' and do not produce any other text.\\nLet's go.\\nMy sentence is: Hummingbirds are known for their incredible speed and agility in flight.\\nWhat do you say?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = parse_reply(resp_text)\n",
    "prompt_B = init_prompt_B.substitute(sentence=sentence)\n",
    "prompt_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3ddeae6-a8e9-4b59-826d-8884c152d213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:34.004739Z",
     "start_time": "2024-02-19T11:10:32.893426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I SAY: In addition to their speed, hummingbirds also have remarkable hovering abilities that allow them to feed on nectar from flowers.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_B, resp_B, resp_B_text = llm.generate_response(add_message([], prompt_B))\n",
    "resp_B_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cb68a4d-2518-4f5f-951c-f304f9dfb301",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:35.839434Z",
     "start_time": "2024-02-19T11:10:35.797528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In addition to their speed, hummingbirds also have remarkable hovering abilities that allow them to feed on nectar from flowers.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_reply(resp_B_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff68b4-c992-49f8-90fb-0e7bcf73e4d1",
   "metadata": {},
   "source": [
    "Alright! Now we need to check this move, both for well-formedness and against the game rules.\n",
    "\n",
    "Here, it would be helpful to already formalise the game state. (Actually, when you're just playing around with an idea, you can postone this. I've only added this after iterating on this a couple of times to get a feel for what I need to keep track of.)\n",
    "\n",
    "To determine whether a move met the game rule, we need to know what letter it was supposed to start with. If it met the rule, we advance the counter of successful moves, and also advance the expected letter. We also check whether we have reached the maximal number of turns. If so, the game is a win. If however the move did not meet the rule, we end the game as a failure. \n",
    "\n",
    "If the attempted move didn't even validate, we abort the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f87ed8af-3d5a-4398-988b-475e3a21bcd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:37.945829Z",
     "start_time": "2024-02-19T11:10:37.922483Z"
    }
   },
   "outputs": [],
   "source": [
    "class InitialsGameState():\n",
    "    def __init__(self, letter):\n",
    "        self.letter = letter\n",
    "        self.n_moves = 0\n",
    "        self.success = False\n",
    "        self.aborted = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ee1eb-d442-4d90-97d7-e2a1c906cd27",
   "metadata": {},
   "source": [
    "Before A's move, the game state was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "409418a2-813d-4d6d-9bb3-d3adee935eb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:40.211641Z",
     "start_time": "2024-02-19T11:10:40.159441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('h', 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_game = InitialsGameState('h')\n",
    "this_game.letter, this_game.n_moves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f04ad4-afdb-4cf5-bec6-7e5740ebf0a8",
   "metadata": {},
   "source": [
    "A's move was successful, so we should increment the letter that we are expecting now. We can define a method for that on the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7421d349-962d-49ac-ac65-0ad5f3ec7ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:42.213970Z",
     "start_time": "2024-02-19T11:10:42.183744Z"
    }
   },
   "outputs": [],
   "source": [
    "class InitialsGameState():\n",
    "    def __init__(self, letter):\n",
    "        self.letter = letter\n",
    "        self.n_moves = 0\n",
    "        self.success = False\n",
    "        self.aborted = False\n",
    "\n",
    "    def increment_state(self):\n",
    "        self.letter = chr(ord(self.letter) + 1 )\n",
    "        self.n_moves += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4079f4-30fa-4fb2-9d71-c0cbcb93ad77",
   "metadata": {},
   "source": [
    "(Since we've redefined the state class, need to set to before A's move again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c77ce995-0d53-421c-8c9f-de0ee00707d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:44.944737Z",
     "start_time": "2024-02-19T11:10:44.917387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_game = InitialsGameState('h')\n",
    "this_game.increment_state()\n",
    "this_game.letter, this_game.n_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bcd1c73-8429-46ce-be89-66ef36481d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:47.276866Z",
     "start_time": "2024-02-19T11:10:47.250303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_move(parse_reply(resp_B_text), letter=this_game.letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3b08d-47c6-479a-a833-9c9879d77d0a",
   "metadata": {},
   "source": [
    "(By now it should be clear that parsing and validating could be methods of the game state, but we'll skip that for now...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93413dcb-cf80-4e75-ba80-295103820fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:49.672957Z",
     "start_time": "2024-02-19T11:10:49.653812Z"
    }
   },
   "outputs": [],
   "source": [
    "this_game.increment_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46eb9690-716c-464a-a808-af86cd6c7e9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:51.882048Z",
     "start_time": "2024-02-19T11:10:51.860037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_game.letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef821fc-b9b0-4645-82d0-2bb5492bba9f",
   "metadata": {},
   "source": [
    "#### The Game Loop\n",
    "\n",
    "Not too bad. From here on, the game consists of giving A the turn (with all previous history), parsing and validating the response, then giving B the turn, parsing and validating the response, and so on, breaking the loop if a) an unparseable move was attempted (more correctly: no understandable move was made), or b) a loosing move was made (wrong initial), or c) the max # of turns has been reached. We are not going to implement that here. We can simulate the loop by going back to A's cell below, and break whenver we run out of patience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71ae0dd8-1718-4e5c-a84d-d4332973ed92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:10:58.512615Z",
     "start_time": "2024-02-19T11:10:58.491999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant'},\n",
       " {'role': 'user',\n",
       "  'content': \"Let us play a game. I will tell you a topic and you will give me a short sentence that fits to this topic.\\nBut I will also tell you a letter. The sentence that you give me has to start with this letter.\\nAfter you have answered, I will give you my reply, which will start with the letter following your letter in the alphabet.\\nThen it is your turn again, to produce a reply starting with the letter following that one. And so on. Let's go.\\nStart your utterance with I SAY: and do no produce any other text.\\nThe topic is: birds\\nThe letter is: h\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I SAY: Hummingbirds are known for their incredible speed and agility in flight.'},\n",
       " {'role': 'user',\n",
       "  'content': 'I SAY: In addition to their speed, hummingbirds also have remarkable hovering abilities that allow them to feed on nectar from flowers.'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt_A = add_message(prompt_A, resp_text, role='assistant')\n",
    "next_prompt_A = add_message(next_prompt_A, resp_B_text, role='user')\n",
    "next_prompt_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2d20f0-c754-42d1-bfe6-e78a020e3587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:11:04.271781Z",
     "start_time": "2024-02-19T11:11:02.112829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I SAY: Jays are known for their intelligence and complex social behaviors.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_A, resp, resp_text = llm.generate_response(next_prompt_A)\n",
    "resp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b258394e-e1a9-406b-aa34-2789d6201f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:11:06.047770Z",
     "start_time": "2024-02-19T11:11:05.986943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAY\n"
     ]
    }
   ],
   "source": [
    "psd_reply = parse_reply(resp_text)\n",
    "if psd_reply:\n",
    "    if check_move(psd_reply, letter=this_game.letter):\n",
    "        print('YAY')\n",
    "    else:\n",
    "        print('LOST')\n",
    "else:\n",
    "    print('NOT WELL-FORMED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba59083b-a96d-4d30-90ba-e68e0fb4a9e3",
   "metadata": {},
   "source": [
    "If we get a non well-formed reply, we could add a reprompting loop (for which we'd need to design a prompt) and try for couple of iteration if we can prise one out of the model... Or immediately break out here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a2f63f7-5d2f-4f69-8d19-ca35324d917a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:11:09.871563Z",
     "start_time": "2024-02-19T11:11:09.842880Z"
    }
   },
   "outputs": [],
   "source": [
    "this_game.increment_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87bd9f1b-24ed-4b3f-9cfa-cc09af6f542b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:11:11.539753Z",
     "start_time": "2024-02-19T11:11:11.511507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant'},\n",
       " {'role': 'user',\n",
       "  'content': \"Let us play a game. I will give you a sentence.\\nThe first word in my sentence starts with a certain letter.\\nI want you to give me a sentence as a reply, with the same topic as my sentence, but different from my sentence.\\nThe first word of your sentence should start with the next letter in the alphabet from the letter my sentence started with.\\nLet us try to have a whole conversation like that.\\nPlease start your reply with 'I SAY:' and do not produce any other text.\\nLet's go.\\nMy sentence is: Hummingbirds are known for their incredible speed and agility in flight.\\nWhat do you say?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'I SAY: In addition to their speed, hummingbirds also have remarkable hovering abilities that allow them to feed on nectar from flowers.'},\n",
       " {'role': 'user',\n",
       "  'content': 'I SAY: Jays are known for their intelligence and complex social behaviors.'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_prompt_B = add_message(prompt_B, resp_B_text, role='assistant')\n",
    "next_prompt_B = add_message(next_prompt_B, resp_text, role='user')\n",
    "next_prompt_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48ca5f50-6e35-4f30-abc5-aca011152c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:11:29.605092Z",
     "start_time": "2024-02-19T11:11:14.753240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I SAY: Kites are fascinating birds of prey that exhibit impressive hunting skills and aerial acrobatics.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_B, resp_B, resp_B_text = llm.generate_response(next_prompt_B)\n",
    "resp_B_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb03fc11-b056-4c50-b313-5f44c05a9a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-19T11:11:29.645637Z",
     "start_time": "2024-02-19T11:11:29.609056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAY\n"
     ]
    }
   ],
   "source": [
    "psd_reply = parse_reply(resp_B_text)\n",
    "if psd_reply:\n",
    "    if check_move(psd_reply, letter=this_game.letter):\n",
    "        print('YAY')\n",
    "    else:\n",
    "        print('LOST')\n",
    "else:\n",
    "    print('NOT WELL-FORMED')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1666e6-660b-4f2b-9bd9-d7a9b965aed1",
   "metadata": {},
   "source": [
    "Ok. If we made it here, we can jump again to the beginning of the loop (see cell above), and just execute the cells again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ffcbe-66e8-4a0f-abdd-3bd68c73f478",
   "metadata": {},
   "source": [
    "Good. Looks like this game has a chance of working with at least one model! (In fact, it looks like this game is too easy, and we'd need to think again about what it really was supposed to show...) \n",
    "\n",
    "To turn this into something that could be run as part of a proper benchmark, we'd now need to do a lot of work wrapping stuff around this, like running it repeated times from different starting letters, logging everything properly, etc. etc.. But fear not! This is what the `clemgame` framework gives you, and what is described in the `howto_add_game_example.ipynb` notebook.\n",
    "\n",
    "Remember: the purpose of this notebook was to show you what the *outcome* of a prototyping session might look like. The actual prototyping will involve trying out various prompts, coming to a better idea of what the game state is and how to represent it, etc. That is, it will look a lot messier. But it might not be a bad idea at the end of your session to clean up what you have, and prepare something that looks more like this notebook. This should form a good basis for then implementing the game properly in the framework.\n",
    "\n",
    "To recap: The basic structure of a game is actually quite simple. At its core, a game consist of a loop like this:\n",
    "\n",
    "```\n",
    "while to_be_continued:\n",
    "    for player in players:\n",
    "        response = play(player, get_view(player, state))\n",
    "        if not valid(response):\n",
    "            break\n",
    "        state = update(state, response)\n",
    "        if lose(state):\n",
    "            break\n",
    "     to_be_continued = check_if_continue(state)\n",
    "```\n",
    "\n",
    "This is pretty much a classic turn-taking loop for multiple players. The only part that is a bit adapted is that each player may get a specific view on the current state. This is where the GameMaster comes in, which can be seen as a mediator sitting in between the players. E.g., in a clue giving game, the GameMaster will tell the first player what to give clues about (that's the \"view\" of player A on the state), and then pass on the clue to player B, but of course not the solution.\n",
    "\n",
    "Since the main purpose, or at least the origins of clembench lie in benchmarking, we have a lot of scaffolding around this that makes it possible to feed particular initial states (= game instances) to this loop, and to log and score the results. But the core, which defines the game, is always this loop: What is being \"explained\" to the players on what they can do (= prompting a model, if the player is realised with an LLM), how the response is parsed as valid move (move rules), how the valid move updates the state (game rules).\n",
    "\n",
    "There are two ways to continue from here. `the_annotated_hellogame.ipynb` takes it more immediately from here, and shows how the game loop is implemented in clemgame, by annotating the simple hellogame (which we just use for testing the setup), successively adding the benchmarking layers around it. `howto_add_game_example.ipynb` starts from the other direction and explains what files need to be in place to have a proper game that can run via the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3526f21c-01cf-489e-bea8-9ab4015f65ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
